{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting index file for year: 2021 remote=https://s3.amazonaws.com/irs-form-990/index_2021.csv local=/opt/conda/miniconda3/lib/python3.8/site-packages/irsx/CSV/index_2021.csv\n",
      "Beginning streaming download of https://s3.amazonaws.com/irs-form-990/index_2021.csv\n",
      "Total file size: 55.76 MB\n",
      "Download completed to /opt/conda/miniconda3/lib/python3.8/site-packages/irsx/CSV/index_2021.csv in 0:00:07.584222\n"
     ]
    }
   ],
   "source": [
    "#Download Index file\n",
    "!irsx_index --year=2021 --verbose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 512 µs (started: 2022-02-02 11:02:53 +00:00)\n"
     ]
    }
   ],
   "source": [
    "# To have time runtime for cells\n",
    "try:\n",
    "    %load_ext autotime\n",
    "except:\n",
    "    !pip install ipython-autotime\n",
    "    %load_ext autotime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.19 s (started: 2022-02-02 11:34:18 +00:00)\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.session import SparkSession\n",
    "import pandas as pd\n",
    "from pyspark.sql.types import StringType\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "\n",
    "path = \"/opt/conda/miniconda3/lib/python3.8/site-packages/irsx/CSV/index_2021.csv\"\n",
    "df21 = pd.read_csv(path, index_col=False, dtype=str) # read all as string, not beautiful but we only need object id anyways\n",
    "\n",
    "sdf = spark.createDataFrame(df21[\"OBJECT_ID\"], StringType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/02/02 11:24:11 WARN org.apache.spark.sql.catalyst.analysis.SimpleFunctionRegistry: The function spark_transform_data replaced a previously registered function.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.<lambda>(z)>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 197 ms (started: 2022-02-02 11:24:11 +00:00)\n"
     ]
    }
   ],
   "source": [
    "from irsx.xmlrunner import XMLRunner\n",
    "from pyspark.sql.types import StringType, StructType, StructField, IntegerType\n",
    "from pyspark.sql.functions import udf\n",
    "\n",
    "xml_runner = XMLRunner()\n",
    "def transform_data(e):\n",
    "    try:\n",
    "        filing = xml_runner.run_filing(e)\n",
    "        schedules = filing.list_schedules()\n",
    "    except:\n",
    "        print(f\"Transform error for id {e}\")\n",
    "        return [\"\",\"\",\"\",\"\",0, 0, 0, 0, 0, 0,0, 0]\n",
    "    \n",
    "    ein = 0\n",
    "    state = 0\n",
    "    name = 0\n",
    "    revenue = 0\n",
    "    revenueEZ = 0\n",
    "    vol_cnt, empl_cnt, rvn_ls_exp, liab_eoy, liab_boy,assts_eoy, assts_boy = 0, 0, 0, 0, 0,0, 0\n",
    "    \n",
    "    if \"ReturnHeader990x\" in schedules:\n",
    "        header = filing.get_parsed_sked(\"ReturnHeader990x\")\n",
    "        header_part_i = header[0][\"schedule_parts\"][\"returnheader990x_part_i\"]\n",
    "        ein = header_part_i[\"ein\"]\n",
    "        state = header_part_i.get(\"USAddrss_SttAbbrvtnCd\", \"XX\")\n",
    "        name = header_part_i[\"BsnssNm_BsnssNmLn1Txt\"]\n",
    "        \n",
    "    if \"IRS990EZ\" in schedules:\n",
    "        irs990ez = filing.get_parsed_sked(\"IRS990EZ\")\n",
    "        irs990ez_part_i = irs990ez[0][\"schedule_parts\"].get(\"ez_part_i\", None)\n",
    "        if irs990ez_part_i:\n",
    "            revenueEZ = irs990ez_part_i.get(\"TtlRvnAmt\", 0)        \n",
    "    \n",
    "    if \"IRS990\" in schedules:\n",
    "        irs990 = filing.get_parsed_sked(\"IRS990\")\n",
    "        irs990_part_i = irs990[0][\"schedule_parts\"][\"part_i\"]\n",
    "        revenue = irs990_part_i[\"CYTtlRvnAmt\"]\n",
    "        vol_cnt = int(irs990_part_i.get(\"TtlVlntrsCnt\", 0))\n",
    "        empl_cnt = int(irs990_part_i.get(\"TtlEmplyCnt\", 0))\n",
    "        rvn_ls_exp = int(irs990_part_i.get(\"CYRvnsLssExpnssAmt\", 0))\n",
    "        liab_eoy = int(irs990_part_i.get(\"TtlLbltsEOYAmt\", 0))\n",
    "        liab_boy = int(irs990_part_i.get(\"TtlLbltsBOYAmt\", 0))\n",
    "        assts_eoy = int(irs990_part_i.get(\"TtlAsstsEOYAmt\", 0))\n",
    "        assts_boy = int(irs990_part_i.get(\"TtlAsstsBOYAmt\", 0))\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    revenue = int(revenue) + int(revenueEZ)\n",
    "    return [e, ein, state, name, revenue, vol_cnt, empl_cnt, rvn_ls_exp, liab_eoy, liab_boy,assts_eoy, assts_boy ]\n",
    "     \n",
    "    \n",
    "my_schema = StructType([\n",
    "    StructField(\"ObjectID\", StringType(), nullable=False),\n",
    "    StructField(\"EIN\", StringType(), nullable=False),\n",
    "    StructField(\"State\", StringType(), nullable=False),\n",
    "    StructField(\"Name\", StringType(), nullable=False),\n",
    "    StructField(\"Revenue\", IntegerType(), nullable=False),\n",
    "    StructField(\"TtlVlntrsCnt\", IntegerType(), nullable=False),\n",
    "    StructField(\"TtlEmplyCnt\", IntegerType(), nullable=False),\n",
    "    StructField(\"CYRvnsLssExpnssAmt\", IntegerType(), nullable=False),\n",
    "    StructField(\"TtlLbltsEOYAmt\", IntegerType(), nullable=False),\n",
    "    StructField(\"TtlLbltsBOYAmt\", IntegerType(), nullable=False),\n",
    "    StructField(\"TtlAsstsEOYAmt\", IntegerType(), nullable=False),\n",
    "    StructField(\"TtlAsstsBOYAmt\", IntegerType(), nullable=False),\n",
    "])\n",
    "\n",
    "spark_transform_data = udf(lambda z: transform_data(z), my_schema)\n",
    "spark.udf.register(\"spark_transform_data\", spark_transform_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "string indices must be integers",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_3040/2965430301.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfiling\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlist_schedules\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mchilds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrecurse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiling\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_parsed_sked\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecurse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_3040/2965430301.py\u001b[0m in \u001b[0;36mrecurse\u001b[0;34m(dict)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecurse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_3040/2965430301.py\u001b[0m in \u001b[0;36mrecurse\u001b[0;34m(dict)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecurse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: string indices must be integers"
     ]
    }
   ],
   "source": [
    "from irsx.xmlrunner import XMLRunner\n",
    "\n",
    "xml_runner = XMLRunner()\n",
    "filing = xml_runner.run_filing(\"202021359349301552\")\n",
    "\n",
    "def recurse(dict):\n",
    "    result = []\n",
    "    for key in dict:\n",
    "        result.append(key)\n",
    "        result.extend(recurse(dict[key]))\n",
    "    return result\n",
    "\n",
    "for e in filing.list_schedules():\n",
    "    childs = recurse(filing.get_parsed_sked(e)[0])\n",
    "    print(recurse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['202032549349200018',\n",
       " '223697708',\n",
       " 'NJ',\n",
       " 'NUTLEY LINCOLN SCHOOL P T O',\n",
       " 90267,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 7.11 ms (started: 2022-02-02 11:16:45 +00:00)\n"
     ]
    }
   ],
   "source": [
    "transform_data(\"202032549349200018\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Sample\n",
    "small_sdf = sdf.sample(0.4, seed=43).repartition(10)\n",
    "anz = small_sdf.count()\n",
    "print(anz)\n",
    "small_sdf2 = small_sdf.withColumn('valuelist', spark_transform_data('value')).select(\"valuelist.*\")\n",
    "#small_sdf2.show()\n",
    "small_sdf.explain()\n",
    "small_sdf2.toPandas().to_csv(f\"BIGData/{anz}.csv\", index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/02/02 11:34:35 WARN org.apache.spark.scheduler.TaskSetManager: Stage 45 contains a task of very large size (2076 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "184781\n",
      "== Physical Plan ==\n",
      "*(2) Project [pythonUDF0#721.ObjectID AS ObjectID#697, pythonUDF0#721.EIN AS EIN#698, pythonUDF0#721.State AS State#699, pythonUDF0#721.Name AS Name#700, pythonUDF0#721.Revenue AS Revenue#701, pythonUDF0#721.TtlVlntrsCnt AS TtlVlntrsCnt#702, pythonUDF0#721.TtlEmplyCnt AS TtlEmplyCnt#703, pythonUDF0#721.CYRvnsLssExpnssAmt AS CYRvnsLssExpnssAmt#704, pythonUDF0#721.TtlLbltsEOYAmt AS TtlLbltsEOYAmt#705, pythonUDF0#721.TtlLbltsBOYAmt AS TtlLbltsBOYAmt#706, pythonUDF0#721.TtlAsstsEOYAmt AS TtlAsstsEOYAmt#707, pythonUDF0#721.TtlAsstsBOYAmt AS TtlAsstsBOYAmt#708]\n",
      "+- BatchEvalPython [<lambda>(value#685)], [pythonUDF0#721]\n",
      "   +- *(1) Scan ExistingRDD[value#685]\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/02/02 11:34:36 WARN org.apache.spark.scheduler.TaskSetManager: Stage 48 contains a task of very large size (2076 KiB). The maximum recommended task size is 1000 KiB.\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 14min 23s (started: 2022-02-02 11:34:34 +00:00)\n"
     ]
    }
   ],
   "source": [
    "# full df\n",
    "anz = sdf.count()\n",
    "print(anz)\n",
    "sdf2 = sdf.withColumn('valuelist', spark_transform_data('value')).select(\"valuelist.*\")\n",
    "sdf2.explain()\n",
    "pdf = sdf2.toPandas()\n",
    "pdf.to_csv(f\"hdfs://big-spark-cluster-m/user/root/{anz}.csv\", index=False)\n",
    "pdf.to_parquet(f\"hdfs://big-spark-cluster-m/user/root/{anz}.parquet\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zeiten von erfolgreichen Läufen\n",
    "\n",
    "|Anzahl | Zeit| Kommentar |  \n",
    "-------|--------|---------------\n",
    "|4710 | time: 2min 44s (started: 2022-01-17 18:46:15 +00:00) | erster Versuch (zusätzlicher Zeitbedarf für Sampling  & lokal)|\n",
    "|46099| time: 12min 22s (started: 2022-01-17 20:42:31 +00:00) | erster Versuch mit ErrorHandling (zusätzlicher Zeitbedarf für Sampling & lokal)|\n",
    "|184781| time: 1h 14min 7s (started: 2022-01-25 12:37:15 +00:00) | -  (zusätzlicher Zeitbedarf für Sampling & lokal)|\n",
    "|184781| time: 14min 23s (started: 2022-02-02 11:34:34 +00:00) | mehr Attribute, dafür kein Samplen mehr sonder direkt beim Einlesen, speichern in HDFS|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start a Sparkession"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Einlesen des Files  \n",
    "Das File kann entweder lokal oder mittels hdfs eingelesen werden  \n",
    "Falls das File lokal eingelesen wird muss es auf jedem Node vorhanden sein, deswegen empfiehlt sich die Verwendung von HDFS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.session import SparkSession\n",
    "spark2 = SparkSession.builder.appName(\"Test1\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _c0: integer (nullable = true)\n",
      " |-- ObjectID: long (nullable = true)\n",
      " |-- EIN: integer (nullable = true)\n",
      " |-- State: string (nullable = true)\n",
      " |-- Name: string (nullable = true)\n",
      " |-- Revenue: integer (nullable = true)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(pyspark.sql.dataframe.DataFrame,\n",
       " None,\n",
       " [Row(_c0=0, ObjectID=202023169349201962, EIN=113463183, State='NY', Name='77th PRECINT COMMUNITY COUNCIL INC', Revenue=3800),\n",
       "  Row(_c0=1, ObjectID=202013049349200436, EIN=202347170, State='MD', Name='SOUTHERN MARYLAND FAST PITCH ORGANIZATION', Revenue=25259),\n",
       "  Row(_c0=2, ObjectID=202120609349300112, EIN=475378165, State='CA', Name='OAKLAND WINE FESTIVAL AND FOUNDATION', Revenue=225),\n",
       "  Row(_c0=3, ObjectID=202100489349300620, EIN=582003159, State='AR', Name='TOTAL LIFE COMMUNITY EDUC FOUNDATION', Revenue=363307),\n",
       "  Row(_c0=4, ObjectID=202023189349306407, EIN=760536563, State='CT', Name='BOZRAH INTERNATIONAL MINISTRIES INC', Revenue=927063)])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fs_path = \"file:///revenue_2021_100.csv\" #local_fs\n",
    "hdfs_path = \"hdfs://big-spark-cluster-m/user/root/46099.csv\" # hdfs\n",
    "df = spark2.read.csv(hdfs_path, header=True, inferSchema=True)\n",
    "\n",
    "type(df), df.printSchema(), df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Aggregation\n",
    "Das DF kann entweder direkt aggregiert werden, oder vorher in ein RDD umgewandelt werden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ",ObjectID,EIN,State,Name,Revenue\n",
      "0,202023169349201962,113463183,NY,77th PRECINT COMMUNITY COUNCIL INC,3800\n",
      "1,202013049349200436,202347170,MD,SOUTHERN MARYLAND FAST PITCH ORGANIZATION,25259\n",
      "2,202120609349300112,475378165,CA,OAKLAND WINE FESTIVAL AND FOUNDATION,225\n",
      "3,202100489349300620,582003159,AR,TOTAL LIFE COMMUNITY EDUC FOUNDATION,363307\n",
      "4,202023189349306407,760536563,CT,BOZRAH INTERNATIONAL MINISTRIES INC,927063\n",
      "5,202043219349317174,822282576,OH,ONECITY FOR RECOVERY INC,51184\n",
      "6,202013219349211076,470873877,LA,Grace Place Ministries Inc,164849\n",
      "7,202110539349200126,870420899,UT,UTAH ACADEMY OF GENERAL DENTISTRY,12617\n",
      "8,202033229349300123,450255772,ND,UNITED WAY OF GRAND FORKS EAST GRAND,565469\n"
     ]
    }
   ],
   "source": [
    "!head BIGData/46099.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- State: string (nullable = true)\n",
      " |-- Revenue: integer (nullable = true)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('NY', 26282974544),\n",
       " ('CA', 22599757286),\n",
       " ('PA', 14021197075),\n",
       " ('MO', 9767605990),\n",
       " ('TX', 8408306891),\n",
       " ('FL', 6441797903),\n",
       " ('OH', 6364770882),\n",
       " ('TN', 6352786890),\n",
       " ('GA', 6155584013),\n",
       " ('MD', 6043965992),\n",
       " ('VA', 5411817304),\n",
       " ('NC', 5311445382),\n",
       " ('WA', 4838719241),\n",
       " ('IL', 4763859142),\n",
       " ('MN', 4430065258),\n",
       " ('IN', 4276565192),\n",
       " ('NJ', 3866619086),\n",
       " ('MA', 3838411645),\n",
       " ('DC', 3286803190),\n",
       " ('MI', 3224375440),\n",
       " ('KY', 3165665585),\n",
       " ('IA', 2725559896),\n",
       " ('NH', 2717014995),\n",
       " ('WI', 2610280298),\n",
       " ('AZ', 2317167743),\n",
       " ('OR', 2296702694),\n",
       " ('SD', 2251631584),\n",
       " ('NE', 2024525833),\n",
       " ('CO', 1986296862),\n",
       " ('ME', 1911403229),\n",
       " ('CT', 1671984299),\n",
       " ('LA', 1642874943),\n",
       " ('DE', 1548520157),\n",
       " ('MT', 1419515866),\n",
       " ('OK', 1255335798),\n",
       " ('XX', 1113835035),\n",
       " ('ID', 1033109314),\n",
       " ('SC', 985934691),\n",
       " ('KS', 956909342),\n",
       " ('AL', 816325971),\n",
       " ('NV', 575109238),\n",
       " ('RI', 569357888),\n",
       " ('VT', 518079533),\n",
       " ('UT', 499304361),\n",
       " ('ND', 488519360),\n",
       " ('WY', 453860239),\n",
       " ('MS', 438280172),\n",
       " ('NM', 434322177),\n",
       " ('WV', 371067524),\n",
       " ('HI', 369879970),\n",
       " ('AK', 221611971),\n",
       " ('AR', 214148178),\n",
       " ('VI', 103234800),\n",
       " ('PR', 22377120),\n",
       " ('AE', 1911788),\n",
       " ('MP', 283051)]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Aggregation als RDD\n",
    "two_col_df = df.drop(\"ObjectID\", \"EIN\", \"Name\", \"RevenueEZ\", \"_c0\") #col _c0 may (not) exist so drop or not drop it\n",
    "two_col_df.printSchema()\n",
    "rdd = two_col_df.rdd\n",
    "\n",
    "from operator import add\n",
    "reduced_rdd = rdd.reduceByKey(add).sortBy(lambda x: x[1], ascending = False)\n",
    "reduced_rdd.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting cartopy\n",
      "  Downloading Cartopy-0.20.2.tar.gz (10.8 MB)\n",
      "     |████████████████████████████████| 10.8 MB 5.0 MB/s            \n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: shapely>=1.6.4 in /opt/conda/miniconda3/lib/python3.8/site-packages (from cartopy) (1.8.0)\n",
      "Collecting pyshp>=2.1\n",
      "  Downloading pyshp-2.1.3.tar.gz (219 kB)\n",
      "     |████████████████████████████████| 219 kB 59.4 MB/s            \n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: matplotlib>=3.1 in /opt/conda/miniconda3/lib/python3.8/site-packages (from cartopy) (3.4.3)\n",
      "Requirement already satisfied: pyproj>=3.0.0 in /opt/conda/miniconda3/lib/python3.8/site-packages (from cartopy) (3.3.0)\n",
      "Requirement already satisfied: numpy>=1.18 in /opt/conda/miniconda3/lib/python3.8/site-packages (from cartopy) (1.19.5)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/miniconda3/lib/python3.8/site-packages (from matplotlib>=3.1->cartopy) (1.3.2)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /opt/conda/miniconda3/lib/python3.8/site-packages (from matplotlib>=3.1->cartopy) (2.4.7)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /opt/conda/miniconda3/lib/python3.8/site-packages (from matplotlib>=3.1->cartopy) (8.4.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/miniconda3/lib/python3.8/site-packages (from matplotlib>=3.1->cartopy) (0.11.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/miniconda3/lib/python3.8/site-packages (from matplotlib>=3.1->cartopy) (2.8.0)\n",
      "Requirement already satisfied: certifi in /opt/conda/miniconda3/lib/python3.8/site-packages (from pyproj>=3.0.0->cartopy) (2021.10.8)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/miniconda3/lib/python3.8/site-packages (from python-dateutil>=2.7->matplotlib>=3.1->cartopy) (1.16.0)\n",
      "Building wheels for collected packages: cartopy, pyshp\n",
      "  Building wheel for cartopy (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for cartopy: filename=Cartopy-0.20.2-cp38-cp38-linux_x86_64.whl size=10978627 sha256=0806ee7e5c0e31a709a4f8a192b3aab102dcc672f08954780e5d4d776702dd4b\n",
      "  Stored in directory: /root/.cache/pip/wheels/71/52/f7/50b33c2f93578d20eb5f5cfc8bc82672919d3dfd14044b6cd5\n",
      "  Building wheel for pyshp (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pyshp: filename=pyshp-2.1.3-py3-none-any.whl size=37324 sha256=ffe09ade21f8c7b8b8b5d64afc0e8c5ec683d0fbc37010dbb5993ec504ed8e08\n",
      "  Stored in directory: /root/.cache/pip/wheels/1f/1b/b5/54affbefc8a7e2bdf1da000fc576b8a1c91338f1f327a04f4c\n",
      "Successfully built cartopy pyshp\n",
      "Installing collected packages: pyshp, cartopy\n",
      "Successfully installed cartopy-0.20.2 pyshp-2.1.3\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/miniconda3/lib/python3.8/site-packages/cartopy/io/__init__.py:241: DownloadWarning: Downloading: https://naturalearth.s3.amazonaws.com/110m_cultural/ne_110m_admin_1_states_provinces_lakes_shp.zip\n",
      "  warnings.warn(f'Downloading: {url}', DownloadWarning)\n"
     ]
    },
    {
     "ename": "HTTPError",
     "evalue": "HTTP Error 404: Not Found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2384/2592556564.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mshapename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'admin_1_states_provinces_lakes_shp'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m states_shp = shpreader.natural_earth(resolution='110m',\n\u001b[0m\u001b[1;32m     13\u001b[0m                                      category='cultural', name=shapename)\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/miniconda3/lib/python3.8/site-packages/cartopy/io/shapereader.py\u001b[0m in \u001b[0;36mnatural_earth\u001b[0;34m(resolution, category, name)\u001b[0m\n\u001b[1;32m    277\u001b[0m     format_dict = {'config': config, 'category': category,\n\u001b[1;32m    278\u001b[0m                    'name': name, 'resolution': resolution}\n\u001b[0;32m--> 279\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mne_downloader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mformat_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    280\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/miniconda3/lib/python3.8/site-packages/cartopy/io/__init__.py\u001b[0m in \u001b[0;36mpath\u001b[0;34m(self, format_dict)\u001b[0m\n\u001b[1;32m    201\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m             \u001b[0;31m# we need to download the file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 203\u001b[0;31m             \u001b[0mresult_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire_resource\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    204\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult_path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/miniconda3/lib/python3.8/site-packages/cartopy/io/shapereader.py\u001b[0m in \u001b[0;36macquire_resource\u001b[0;34m(self, target_path, format_dict)\u001b[0m\n\u001b[1;32m    331\u001b[0m         \u001b[0murl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mformat_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 333\u001b[0;31m         \u001b[0mshapefile_online\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_urlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    334\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    335\u001b[0m         \u001b[0mzfh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mZipFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshapefile_online\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/miniconda3/lib/python3.8/site-packages/cartopy/io/__init__.py\u001b[0m in \u001b[0;36m_urlopen\u001b[0;34m(self, url)\u001b[0m\n\u001b[1;32m    240\u001b[0m         \"\"\"\n\u001b[1;32m    241\u001b[0m         \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Downloading: {url}'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDownloadWarning\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 242\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0murlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    243\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/miniconda3/lib/python3.8/urllib/request.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[1;32m    220\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m         \u001b[0mopener\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_opener\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 222\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mopener\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    223\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0minstall_opener\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/miniconda3/lib/python3.8/urllib/request.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[1;32m    529\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mprocessor\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_response\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mmeth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocessor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 531\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmeth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    532\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    533\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/miniconda3/lib/python3.8/urllib/request.py\u001b[0m in \u001b[0;36mhttp_response\u001b[0;34m(self, request, response)\u001b[0m\n\u001b[1;32m    638\u001b[0m         \u001b[0;31m# request was successfully received, understood, and accepted.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    639\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m200\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mcode\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 640\u001b[0;31m             response = self.parent.error(\n\u001b[0m\u001b[1;32m    641\u001b[0m                 'http', request, response, code, msg, hdrs)\n\u001b[1;32m    642\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/miniconda3/lib/python3.8/urllib/request.py\u001b[0m in \u001b[0;36merror\u001b[0;34m(self, proto, *args)\u001b[0m\n\u001b[1;32m    567\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhttp_err\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    568\u001b[0m             \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'default'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'http_error_default'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0morig_args\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 569\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_chain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    570\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m \u001b[0;31m# XXX probably also want an abstract factory that knows when it makes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/miniconda3/lib/python3.8/urllib/request.py\u001b[0m in \u001b[0;36m_call_chain\u001b[0;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[1;32m    500\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhandler\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mhandlers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    501\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 502\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    503\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    504\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/miniconda3/lib/python3.8/urllib/request.py\u001b[0m in \u001b[0;36mhttp_error_default\u001b[0;34m(self, req, fp, code, msg, hdrs)\u001b[0m\n\u001b[1;32m    647\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mHTTPDefaultErrorHandler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBaseHandler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    648\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mhttp_error_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhdrs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 649\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mHTTPError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhdrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    650\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    651\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mHTTPRedirectHandler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBaseHandler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mHTTPError\u001b[0m: HTTP Error 404: Not Found"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAb4AAAD0CAYAAADkOUNXAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAD9UlEQVR4nO3YsW3DQBBFQZ7hElyKi2DJLoLs5Ho4NyAxkmjAbyb9yWYP2LHW2gCg4uOvDwCAOwkfACnCB0CK8AGQInwApAgfACmfV+O+72vOedctAPAS53mea63vR9tl+Oac23Ec77kKAN5kjPF08+oEIEX4AEgRPgBShA+AFOEDIEX4AEgRPgBShA+AFOEDIEX4AEgRPgBShA+AFOEDIEX4AEgRPgBShA+AFOEDIEX4AEgRPgBShA+AFOEDIEX4AEgRPgBShA+AFOEDIEX4AEgRPgBShA+AFOEDIEX4AEgRPgBShA+AFOEDIEX4AEgRPgBShA+AFOEDIEX4AEgRPgBShA+AFOEDIEX4AEgRPgBShA+AFOEDIEX4AEgRPgBShA+AFOEDIEX4AEgRPgBShA+AFOEDIEX4AEgRPgBShA+AFOEDIEX4AEgRPgBShA+AFOEDIEX4AEgRPgBShA+AFOEDIEX4AEgRPgBShA+AFOEDIEX4AEgRPgBShA+AFOEDIEX4AEgRPgBShA+AFOEDIEX4AEgRPgBShA+AFOEDIEX4AEgRPgBShA+AFOEDIEX4AEgRPgBShA+AFOEDIEX4AEgRPgBShA+AFOEDIEX4AEgRPgBShA+AFOEDIEX4AEgRPgBShA+AFOEDIEX4AEgRPgBShA+AFOEDIEX4AEgRPgBShA+AFOEDIEX4AEgRPgBShA+AFOEDIEX4AEgRPgBShA+AFOEDIEX4AEgRPgBShA+AFOEDIEX4AEgRPgBShA+AFOEDIEX4AEgRPgBShA+AFOEDIEX4AEgRPgBShA+AFOEDIEX4AEgRPgBShA+AFOEDIEX4AEgRPgBShA+AFOEDIEX4AEgRPgBShA+AFOEDIEX4AEgRPgBShA+AFOEDIEX4AEgRPgBShA+AFOEDIEX4AEgRPgBShA+AFOEDIEX4AEgRPgBShA+AFOEDIEX4AEgRPgBShA+AFOEDIEX4AEgRPgBShA+AFOEDIEX4AEgRPgBShA+AFOEDIEX4AEgRPgBShA+AFOEDIEX4AEgRPgBShA+AFOEDIEX4AEgRPgBShA+AFOEDIEX4AEgRPgBShA+AFOEDIEX4AEgRPgBShA+AFOEDIEX4AEgRPgBShA+AFOEDIEX4AEgRPgBShA+AFOEDIEX4AEgRPgBShA+AFOEDIEX4AEgRPgBShA+AFOEDIEX4AEgRPgBShA+AFOEDIEX4AEgRPgBShA+AFOEDIEX4AEgRPgBShA+AFOEDIEX4AEgRPgBShA+AFOEDIEX4AEgRPgBShA+AlLHWej6O8bNt29d95wDAS8y11v5ouAwfAPw3Xp0ApAgfACnCB0CK8AGQInwApPwC5l8gDGfWzGIAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "!pip install cartopy\n",
    "import matplotlib.pyplot as plt\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.io.shapereader as shpreader\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_axes([0, 0, 1, 1], projection=ccrs.LambertConformal())\n",
    "\n",
    "ax.set_extent([-125, -66.5, 20, 50], ccrs.Geodetic())\n",
    "\n",
    "shapename = 'admin_1_states_provinces_lakes_shp'\n",
    "states_shp = shpreader.natural_earth(resolution='110m',\n",
    "                                     category='cultural', name=shapename)\n",
    "\n",
    "popdensity = {\n",
    "    'New Jersey':  438.00,\n",
    "    'Rhode Island':   387.35,\n",
    "    'Massachusetts':   312.68,\n",
    "    'Connecticut':    271.40,\n",
    "    'Maryland':   209.23,\n",
    "    'New York':    155.18,\n",
    "    'Delaware':    154.87,\n",
    "    'Florida':     114.43,\n",
    "    'Ohio':  107.05,\n",
    "    'Pennsylvania':  105.80,\n",
    "    'Illinois':    86.27,\n",
    "    'California':  83.85,\n",
    "    'Virginia':    69.03,\n",
    "    'Michigan':    67.55,\n",
    "    'Indiana':    65.46,\n",
    "    'North Carolina':  63.80,\n",
    "    'Georgia':     54.59,\n",
    "    'Tennessee':   53.29,\n",
    "    'New Hampshire':   53.20,\n",
    "    'South Carolina':  51.45,\n",
    "    'Louisiana':   39.61,\n",
    "    'Kentucky':   39.28,\n",
    "    'Wisconsin':  38.13,\n",
    "    'Washington':  34.20,\n",
    "    'Alabama':     33.84,\n",
    "    'Missouri':    31.36,\n",
    "    'Texas':   30.75,\n",
    "    'West Virginia':   29.00,\n",
    "    'Vermont':     25.41,\n",
    "    'Minnesota':  23.86,\n",
    "    'Mississippi':   23.42,\n",
    "    'Iowa':  20.22,\n",
    "    'Arkansas':    19.82,\n",
    "    'Oklahoma':    19.40,\n",
    "    'Arizona':     17.43,\n",
    "    'Colorado':    16.01,\n",
    "    'Maine':  15.95,\n",
    "    'Oregon':  13.76,\n",
    "    'Kansas':  12.69,\n",
    "    'Utah':  10.50,\n",
    "    'Nebraska':    8.60,\n",
    "    'Nevada':  7.03,\n",
    "    'Idaho':   6.04,\n",
    "    'New Mexico':  5.79,\n",
    "    'South Dakota':  3.84,\n",
    "    'North Dakota':  3.59,\n",
    "    'Montana':     2.39,\n",
    "    'Wyoming':      1.96}\n",
    "\n",
    "ax.background_patch.set_visible(False)\n",
    "ax.outline_patch.set_visible(False)\n",
    "\n",
    "ax.set_title('State Population Density')\n",
    "\n",
    "#for state in shpreader.Reader(states_shp).geometries():\n",
    "for astate in shpreader.Reader(states_shp).records():\n",
    "\n",
    "    ### You want to replace the following code with code that sets the\n",
    "    ### facecolor as a gradient based on the population density above\n",
    "    #facecolor = [0.9375, 0.9375, 0.859375]\n",
    "\n",
    "    edgecolor = 'black'\n",
    "\n",
    "    try:\n",
    "        # use the name of this state to get pop_density\n",
    "        state_dens = popdensity[ astate.attributes['name'] ]\n",
    "    except:\n",
    "        state_dens = 0\n",
    "\n",
    "    # simple scheme to assign color to each state\n",
    "    if state_dens < 40:\n",
    "        facecolor = \"lightyellow\"\n",
    "    elif state_dens > 200:\n",
    "        facecolor = \"red\"\n",
    "    else:\n",
    "        facecolor = \"pink\"\n",
    "\n",
    "    # `astate.geometry` is the polygon to plot\n",
    "    ax.add_geometries([astate.geometry], ccrs.PlateCarree(),\n",
    "                      facecolor=facecolor, edgecolor=edgecolor)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df= pd.read_csv(\"BIGData/184781.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_parquet(\"184781.parquet\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "python",
   "name": "pyspark"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
