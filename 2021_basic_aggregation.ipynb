{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/anaconda/lib/python3.6/site-packages/IPython/core/interactiveshell.py:3072: DtypeWarning: Columns (6) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df21 = pd.read_csv(\"/opt/conda/anaconda/lib/python3.6/site-packages/irsx/CSV/index_2021.csv\",index_col=False)\n",
    "object_ids = df21[\"OBJECT_ID\"].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([202010659349301301, 202010729349300041, 202010729349300021,\n",
       "       202010729349300836, 202000669349300135, 202000669349301125,\n",
       "       202000669349301320, 202000669349301850, 202000669349300905,\n",
       "       202000669349300700, 202000669349300425, 202000679349300505,\n",
       "       202000679349300405, 202000679349300210, 202020669349300127,\n",
       "       202000729349300710, 202020689349300402, 202030699349301268,\n",
       "       202000699349300330, 202000699349300740, 202010679349300301,\n",
       "       202020699349301072, 202020699349300617, 202030709349300313,\n",
       "       202000709349301455, 202000709349300200, 202000709349300520,\n",
       "       202010699349301266, 202010699349300541, 202000719349301035,\n",
       "       202010709349300601, 202010709349301231, 202010709349300931,\n",
       "       202010709349301506, 202020719349300727, 202010719349300816,\n",
       "       202010719349301566, 202010719349301446, 202040699349300954,\n",
       "       202040669349300604, 202040709349301429, 202040719349301204,\n",
       "       202020589349300437, 202020589349300007, 202020589349301312,\n",
       "       202000529349300310, 202000529349301310, 202000529349301205,\n",
       "       202000529349300925, 202000529349300815, 202000529349300710,\n",
       "       202010529349300926, 202020529349300707, 202030529349301113,\n",
       "       202030529349300723, 202020539349300517, 202000559349300130,\n",
       "       202010559349300321, 202010559349301536, 202010559349301346,\n",
       "       202020559349300107, 202020559349301602, 202030559349300003,\n",
       "       202030559349301513, 202010569349301141, 202010569349300601,\n",
       "       202020569349301492, 202020569349301857, 202030569349300118,\n",
       "       202030569349301123, 202030569349300508, 202000579349301125,\n",
       "       202000579349300630, 202000579349300605, 202000579349300100,\n",
       "       202000579349300010, 202000579349301645, 202010579349301116,\n",
       "       202010579349300611, 202020579349300812, 202030579349300943,\n",
       "       202030579349301023, 202021369349201562, 202021369349201617,\n",
       "       202021369349201687, 202021369349201742, 202021369349201777,\n",
       "       202021369349201827, 202021369349201927, 202021369349201942,\n",
       "       202021369349202007, 202021369349202057, 202021369349202162,\n",
       "       202021369349202262, 202021379349100207, 202021379349100307,\n",
       "       202021379349100602, 202021379349200022, 202021379349200512,\n",
       "       202032549349200018])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "object_ids_s = object_ids[:100]\n",
    "object_ids_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ObjectID</th>\n",
       "      <th>EIN</th>\n",
       "      <th>State</th>\n",
       "      <th>Name</th>\n",
       "      <th>Revenue</th>\n",
       "      <th>RevenueEZ</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>202010659349301301</td>\n",
       "      <td>452772761</td>\n",
       "      <td>NJ</td>\n",
       "      <td>CAMDEN'S CHARTER SCHOOL</td>\n",
       "      <td>5148336</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>202010729349300041</td>\n",
       "      <td>237061115</td>\n",
       "      <td>MS</td>\n",
       "      <td>JACKSON STATE UNIVERSITY</td>\n",
       "      <td>10386900</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>202010729349300021</td>\n",
       "      <td>344427516</td>\n",
       "      <td>OH</td>\n",
       "      <td>TIFFIN UNIVERSITY</td>\n",
       "      <td>64789812</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>202010729349300836</td>\n",
       "      <td>840865247</td>\n",
       "      <td>CO</td>\n",
       "      <td>NETWORK MINISTRIES INC</td>\n",
       "      <td>218029</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>202000669349300135</td>\n",
       "      <td>205647589</td>\n",
       "      <td>SC</td>\n",
       "      <td>FAMILY PROMISE OF BEAUFORT COUNTY</td>\n",
       "      <td>482668</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>202021379349100307</td>\n",
       "      <td>412209842</td>\n",
       "      <td>GA</td>\n",
       "      <td>LOVE PEACE AND PROSPERITY INTERNATIONAL INC</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>202021379349100602</td>\n",
       "      <td>136216916</td>\n",
       "      <td>FL</td>\n",
       "      <td>SIMON AND STELLA SHEIB FOUNDATION</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>202021379349200022</td>\n",
       "      <td>202272015</td>\n",
       "      <td>SC</td>\n",
       "      <td>ALPHA SIGMA PHI FRATERNITY INC</td>\n",
       "      <td>0</td>\n",
       "      <td>198372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>202021379349200512</td>\n",
       "      <td>431336280</td>\n",
       "      <td>MO</td>\n",
       "      <td>MISSOURI DAIRY ASSOCIATIONINC</td>\n",
       "      <td>0</td>\n",
       "      <td>94662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>202032549349200018</td>\n",
       "      <td>223697708</td>\n",
       "      <td>NJ</td>\n",
       "      <td>NUTLEY LINCOLN SCHOOL P T O</td>\n",
       "      <td>0</td>\n",
       "      <td>90267</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              ObjectID        EIN State  \\\n",
       "0   202010659349301301  452772761    NJ   \n",
       "1   202010729349300041  237061115    MS   \n",
       "2   202010729349300021  344427516    OH   \n",
       "3   202010729349300836  840865247    CO   \n",
       "4   202000669349300135  205647589    SC   \n",
       "..                 ...        ...   ...   \n",
       "95  202021379349100307  412209842    GA   \n",
       "96  202021379349100602  136216916    FL   \n",
       "97  202021379349200022  202272015    SC   \n",
       "98  202021379349200512  431336280    MO   \n",
       "99  202032549349200018  223697708    NJ   \n",
       "\n",
       "                                           Name   Revenue RevenueEZ  \n",
       "0                       CAMDEN'S CHARTER SCHOOL   5148336         0  \n",
       "1                      JACKSON STATE UNIVERSITY  10386900         0  \n",
       "2                             TIFFIN UNIVERSITY  64789812         0  \n",
       "3                        NETWORK MINISTRIES INC    218029         0  \n",
       "4             FAMILY PROMISE OF BEAUFORT COUNTY    482668         0  \n",
       "..                                          ...       ...       ...  \n",
       "95  LOVE PEACE AND PROSPERITY INTERNATIONAL INC         0         0  \n",
       "96            SIMON AND STELLA SHEIB FOUNDATION         0         0  \n",
       "97               ALPHA SIGMA PHI FRATERNITY INC         0    198372  \n",
       "98                MISSOURI DAIRY ASSOCIATIONINC         0     94662  \n",
       "99                  NUTLEY LINCOLN SCHOOL P T O         0     90267  \n",
       "\n",
       "[100 rows x 6 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from irsx.xmlrunner import XMLRunner\n",
    "xml_runner = XMLRunner()\n",
    "list_all = []\n",
    "for e in object_ids_s:\n",
    "    filing = xml_runner.run_filing(e)\n",
    "    schedules = filing.list_schedules()\n",
    "    \n",
    "    ein = 0\n",
    "    state = 0\n",
    "    name = 0\n",
    "    revenue = 0\n",
    "    revenueEZ = 0\n",
    "    \n",
    "    if \"ReturnHeader990x\" in schedules:\n",
    "        header = filing.get_parsed_sked(\"ReturnHeader990x\")\n",
    "        #print(len(header))\n",
    "        header_part_i = header[0][\"schedule_parts\"][\"returnheader990x_part_i\"]\n",
    "        #print(header_part_i)\n",
    "        ein = header_part_i[\"ein\"]\n",
    "        try:\n",
    "            state = header_part_i[\"USAddrss_SttAbbrvtnCd\"]\n",
    "        except KeyError:\n",
    "            state = XX\n",
    "        name = header_part_i[\"BsnssNm_BsnssNmLn1Txt\"]\n",
    "        #print(ein, state, name)\n",
    "        \n",
    "    if \"IRS990EZ\" in schedules:\n",
    "        irs990ez = filing.get_parsed_sked(\"IRS990EZ\")\n",
    "        irs990ez_part_i = irs990ez[0][\"schedule_parts\"][\"ez_part_i\"]\n",
    "        revenueEZ = irs990ez_part_i[\"TtlRvnAmt\"]        \n",
    "    \n",
    "    if \"IRS990\" in schedules:\n",
    "        irs990 = filing.get_parsed_sked(\"IRS990\")\n",
    "        #print(len(irs990))\n",
    "        irs990_part_i = irs990[0][\"schedule_parts\"][\"part_i\"]\n",
    "        revenue = irs990_part_i[\"CYTtlRvnAmt\"]\n",
    "        #print(revenue)\n",
    "        \n",
    "    list = [e, ein, state, name, revenue, revenueEZ]\n",
    "    list_all.append(list)\n",
    "    \n",
    "df_result = pd.DataFrame(list_all, columns =['ObjectID', 'EIN', 'State', 'Name', 'Revenue', 'RevenueEZ'])\n",
    "df_result.to_csv('revenue_2021_100.csv', index = False)\n",
    "df_result\n",
    "  \n",
    "\n",
    "        \n",
    "    #print(e, ein, state, name, revenue, revenueEZ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start a Sparkession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext\n",
    "from pyspark.sql.session import SparkSession\n",
    "sc = SparkContext(appName=\"BigDataIRS2\")\n",
    "spark = SparkSession(sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Einlesen des Files  \n",
    "Das File kann entweder lokal oder mittels hdfs eingelesen werden  \n",
    "Falls das File lokal eingelesen wird muss es auf jedem Node vorhanden sein, deswegen empfiehlt sich die Verwendung von HDFS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs_path = \"file:///spark_csv/revenue_2021_100.csv\" #local_fs\n",
    "hdfs_path = \"hdfs://spark-jupyter-m/user/hdfs/spark_csv/revenue_2021_100.csv\" # hdfs\n",
    "df = spark.read.csv(hdfs_path, header=True, inferSchema = True)\n",
    "\n",
    "type(df), df.printSchema(), df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Aggregation\n",
    "Das DF kann entweder direkt aggregiert werden, oder vorher in ein RDD umgewandelt werden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-7316af7dadb6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Aggregation als DF\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mgrouped_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"State\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Revenue\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Sum(Revenue)\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mascending\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Aggregation als RDD\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mrdd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrdd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ObjectID\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"EIN\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Name\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"RevenueEZ\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# U\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "# Aggregation als DF\n",
    "grouped_df = df.groupby(\"State\").sum(\"Revenue\").sort(\"Sum(Revenue)\", ascending = False)\n",
    "\n",
    "# Aggregation als RDD\n",
    "rdd = df.rdd.drop(\"ObjectID\", \"EIN\", \"Name\", \"RevenueEZ\") # U\n",
    "from operator import add\n",
    "reduced_rdd = rdd.reduceByKey(add).sortBy(lambda x: x[1], ascending = False)\n",
    "reduced_rdd.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from google.cloud import storage\n",
    "#client = storage.Client()\n",
    "# https://console.cloud.google.com/storage/browser/[bucket-id]/\n",
    "#bucket = client.get_bucket('sparkbucket02')\n",
    "# Then do other things...\n",
    "#blob = bucket.get_blob(\"revenue_2021_100.csv\") #('remote/path/to/file.txt')\n",
    "\n",
    "#df = pd.read_csv(blob.download_as_string())\n",
    "#df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#spark = SparkSession \\\n",
    "#    .builder \\\n",
    "#    .appName(\"Protob Conversion to Parquet\") \\\n",
    "#    .config(\"spark.some.config.option\", \"some-value\") \\\n",
    "#    .getOrCreate()\\\n",
    "\n",
    "#df = spark.read.csv('/home/hadoop/observations_temp.csv, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sudo su - hdfs  \n",
    "hdfs dfsadmin -safemode leave  \n",
    "\n",
    "hdfs dfs -mkdir spark_csv  \n",
    "hdfs dfs -put /spark_csv/revenue_2021_100.csv spark_csv/revenue_2021_100.csv  \n",
    "hdfs dfs -ls spark_csv  \n",
    "\n",
    "https://stackoverflow.com/questions/42091575/pyspark-load-file-path-does-not-exist\n",
    "https://stackoverflow.com/questions/33055403/how-to-navigate-directories-in-hadoop-hdfs\n",
    "https://stackoverflow.com/questions/28213116/hadoop-copy-a-local-file-system-folder-to-hdfs\n",
    "https://stackoverflow.com/questions/61197811/can-i-read-csv-files-from-google-storage-using-spark-in-more-than-one-executor\n",
    "https://groups.google.com/g/cloud-dataproc-discuss/c/cubkWrjkk2g?pli=1\n",
    "https://stackoverflow.com/questions/56448009/storing-source-file-in-google-dataproc-hdfs-vs-google-cloud-storagegoogle-bucke\n",
    "\n",
    "hdfs dfs -put /spark_csv/revenue_2021_100.csv /user/root/spark_csv/revenue_2021_100.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
